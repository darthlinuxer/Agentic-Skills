# Prompt: An√°lise e Simplifica√ß√£o do Ecossistema de Skills e Agentes

> **Objetivo**: Avaliar, analisar e simplificar o ecossistema de skills e agents atrav√©s de an√°lise de dom√≠nio, identifica√ß√£o de duplica√ß√µes, invas√£o de fun√ß√µes e propostas de consolida√ß√£o para tornar o sistema mais enxuto, conciso e objetivo.

---

## üéØ Contexto e Escopo

### Estrutura do Ecossistema

O ecossistema est√° distribu√≠do em **3 plataformas isoladas**:

```
/workspace/
‚îú‚îÄ‚îÄ .agent/          # Plataforma Antigravity (Gemini/Windsurf)
‚îÇ   ‚îú‚îÄ‚îÄ agents/      # 20 agentes especialistas
‚îÇ   ‚îú‚îÄ‚îÄ skills/      # ~75 skills (SKILL.md)
‚îÇ   ‚îú‚îÄ‚îÄ workflows/   # 17 workflows
‚îÇ   ‚îî‚îÄ‚îÄ rules/       # 4 regras globais
‚îÇ
‚îú‚îÄ‚îÄ .claude/         # Plataforma Claude
‚îÇ   ‚îú‚îÄ‚îÄ agents/      # 20 agentes especialistas
‚îÇ   ‚îú‚îÄ‚îÄ skills/      # ~75 skills (SKILL.md)
‚îÇ   ‚îî‚îÄ‚îÄ commands/    # 17 comandos
‚îÇ
‚îî‚îÄ‚îÄ .cursor/         # Plataforma Cursor
    ‚îú‚îÄ‚îÄ agents/      # 20 agentes especialistas
    ‚îú‚îÄ‚îÄ skills/      # ~75 skills (SKILL.mdc)
    ‚îú‚îÄ‚îÄ commands/    # 17 comandos
    ‚îî‚îÄ‚îÄ rules/       # 4 regras globais
```

### Princ√≠pios Fundamentais

1. **Isolamento de Plataformas**: As 3 plataformas devem permanecer isoladas e independentes
2. **Conte√∫do Espelhado**: Apesar de metadatas diferentes, o conte√∫do √© similar entre plataformas
3. **Modifica√ß√£o Sincronizada**: Altera√ß√µes em uma skill/agent devem ser replicadas nas equivalentes
4. **Links Auto-contidos**: Todos os links devem referenciar apenas a pr√≥pria plataforma
5. **Sem Documentos √ìrf√£os**: Nenhum documento deve ficar sem refer√™ncias ap√≥s simplifica√ß√µes

---

## üìä Fase 1: An√°lise de Dom√≠nio e Invent√°rio

### 1.1 Mapeamento de Agentes

**Objetivo**: Identificar sobreposi√ß√µes de responsabilidade entre agentes

**An√°lise Requerida**:

| An√°lise | Descri√ß√£o | M√©trica |
|---------|-----------|---------|
| **Cobertura de Dom√≠nio** | Identificar dom√≠nios cobertos por cada agente | Lista de dom√≠nios por agente |
| **Sobreposi√ß√£o de Expertise** | Detectar agentes com √°reas de expertise id√™nticas ou muito similares | % de overlap entre pares |
| **Ambiguidade de Ativa√ß√£o** | Verificar se triggers de ativa√ß√£o s√£o √∫nicos | Score de ambiguidade (0-100) |
| **Utiliza√ß√£o Real** | Analisar frequ√™ncia de uso (se dados dispon√≠veis) | Ranking de uso |
| **Depend√™ncias de Skills** | Mapear quais skills cada agente utiliza | Grafo de depend√™ncias |

**Perguntas Cr√≠ticas**:
- [ ] Existem agentes com descri√ß√µes muito similares que confundem a LLM?
- [ ] H√° agentes que nunca s√£o ativados por falta de clareza de escopo?
- [ ] Existem pares de agentes que poderiam ser mesclados sem perda de funcionalidade?
- [ ] Algum agente tem escopo t√£o amplo que invade territ√≥rio de outros?
- [ ] Existem agentes com escopo t√£o estreito que poderiam ser skills ao inv√©s?

**Candidatos para An√°lise de Merge**:
```
Analisar especialmente:
- backend-specialist vs database-architect
- test-engineer vs qa-automation-engineer
- product-manager vs product-owner
- documentation-writer vs code-archaeologist (se houver overlap)
- performance-optimizer vs devops-engineer (na √°rea de performance)
```

### 1.2 Mapeamento de Skills

**Objetivo**: Identificar duplica√ß√£o de conte√∫do e invas√£o funcional entre skills

**An√°lise Requerida**:

| An√°lise | Descri√ß√£o | M√©trica |
|---------|-----------|---------|
| **Taxonomia de Dom√≠nios** | Classificar skills por dom√≠nio t√©cnico | √Årvore de categoriza√ß√£o |
| **Similaridade de Conte√∫do** | Comparar conte√∫do normalizado entre skills | Score de similaridade (0-100%) |
| **Overlap Funcional** | Identificar skills que ensinam as mesmas pr√°ticas | Lista de overlaps |
| **Completude Individual** | Verificar se cada skill √© auto-suficiente | % de completude |
| **Refer√™ncias Cruzadas** | Mapear skills que referenciam outras | Grafo de depend√™ncias |
| **Scripts e Automa√ß√µes** | Inventariar scripts por skill | Lista de scripts ativos |
| **Tamanho e Complexidade** | Medir linhas de c√≥digo/documenta√ß√£o | M√©tricas de tamanho |

**Perguntas Cr√≠ticas**:
- [ ] Existem skills com conte√∫do >80% id√™ntico que deveriam ser mescladas?
- [ ] H√° skills muito gen√©ricas que deveriam ser divididas?
- [ ] Existem skills muito espec√≠ficas que deveriam ser se√ß√µes de outras?
- [ ] Alguma skill tem escopo t√£o amplo que deveria ser um agente?
- [ ] Existem skills √≥rf√£s (nunca referenciadas por agentes)?
- [ ] H√° duplica√ß√£o de scripts entre skills diferentes?

**Categorias para An√°lise Espec√≠fica**:

**Frontend (5-7 skills)**:
```
Analisar duplica√ß√£o entre:
- nextjs-react-expert vs frontend-development
- web-design-guidelines vs frontend-design
- ui-ux-pro-max vs frontend-design
- tailwind-patterns vs ui-styling
```

**Backend (4-6 skills)**:
```
Analisar duplica√ß√£o entre:
- api-patterns vs backend-development
- nodejs-best-practices vs backend-development
- python-patterns (se backend-related)
```

**Database (2-3 skills)**:
```
Analisar se database-design √© suficiente ou se h√° overlap
```

**Testing (5-6 skills)**:
```
Analisar duplica√ß√£o entre:
- testing-patterns vs test-driven-development
- tdd-workflow vs test-driven-development
- webapp-testing (espec√≠fico) vs testing-patterns (gen√©rico)
```

**Game Development (7-8 skills)**:
```
Analisar se todas s√£o necess√°rias:
- game-development (gen√©rico)
- game-design, game-audio, game-art (espec√≠ficos)
- 2d-games, 3d-games, pc-games, web-games, mobile-games (plataformas)
- multiplayer (feature-specific)

Poss√≠vel consolida√ß√£o: game-development como core + especializa√ß√µes
```

**Architecture & Planning (4+ skills)**:
```
Analisar duplica√ß√£o entre:
- app-builder vs architecture
- plan-writing vs brainstorming
- problem-solving vs sequential-thinking
```

**Meta-Skills (criar/migrar)**:
```
Analisar necessidade de todas:
- create-skill, create-rule, create-subagent
- migrate-to-skills
- using-superpowers

Podem ser consolidadas em uma √∫nica "meta-development" skill?
```

### 1.3 An√°lise de Rules e Commands

**Rules (4)**:
```
- coding-style
- gemini (orquestra√ß√£o master)
- git
- toc (navega√ß√£o)
```

**Perguntas**:
- [ ] H√° overlap entre coding-style e clean-code (que √© skill)?
- [ ] A rule "toc" poderia ser um script ao inv√©s de rule?

**Commands/Workflows (17)**:
```
Analisar duplica√ß√£o funcional entre:
- brainstorm vs plan
- create vs implement
- enhance vs refactor
- debug vs fix
```

---

## üîç Fase 2: Detec√ß√£o de Problemas Espec√≠ficos

### 2.1 Invas√£o de Fun√ß√µes

**Defini√ß√£o**: Quando um agente/skill executa fun√ß√µes que s√£o responsabilidade prim√°ria de outro

**Como Detectar**:

```python
# Algoritmo de Detec√ß√£o de Invas√£o
Para cada par (A, B) de agentes/skills:
  1. Extrair dom√≠nios de A e B
  2. Calcular overlap: intersection(domains_A, domains_B)
  3. Se overlap > 40%:
     - Se A √© mais espec√≠fico que B: OK (especializa√ß√£o)
     - Se A e B est√£o no mesmo n√≠vel: INVAS√ÉO DETECTADA
  4. Analisar descri√ß√µes e conte√∫do com NLP/embedding similarity
  5. Gerar relat√≥rio de invas√£o com score
```

**Output Esperado**:
```markdown
## Relat√≥rio de Invas√£o de Fun√ß√µes

### Alta Severidade (>60% overlap)
- **backend-specialist** invade **database-architect** em: schema design, migrations
- **frontend-design** invade **ui-ux-pro-max** em: color systems, typography

### M√©dia Severidade (40-60% overlap)
- **testing-patterns** invade **tdd-workflow** em: test structure, AAA pattern

### Baixa Severidade (20-40% overlap)
- ...
```

### 2.2 Duplica√ß√£o de Conte√∫do

**Defini√ß√£o**: Quando 2+ skills/agents cont√™m conte√∫do id√™ntico ou muito similar

**Como Detectar**:

```python
# Algoritmo de Detec√ß√£o de Duplica√ß√£o
Para cada par (SkillA, SkillB):
  1. Normalizar conte√∫do (remover metadata, whitespace, platform refs)
  2. Calcular hash similarity ou embedding distance
  3. Se similarity > 80%:
     - DUPLICA√á√ÉO COMPLETA ‚Üí Merge obrigat√≥rio
  4. Se similarity > 60%:
     - DUPLICA√á√ÉO PARCIAL ‚Üí Analisar se√ß√µes espec√≠ficas
  5. Extrair se√ß√µes duplicadas espec√≠ficas
  6. Gerar relat√≥rio de duplica√ß√£o
```

**Output Esperado**:
```markdown
## Relat√≥rio de Duplica√ß√£o de Conte√∫do

### Duplica√ß√£o Completa (>80% similar)
- **test-driven-development** e **tdd-workflow**: 95% id√™nticos
  - Proposta: Manter test-driven-development, deprecar tdd-workflow

### Duplica√ß√£o Parcial (60-80% similar)
- **frontend-design** e **ui-ux-pro-max**: 72% similar
  - Se√ß√µes duplicadas: Color Systems, Typography Rules
  - Proposta: Consolidar se√ß√µes comuns, especializar diferen√ßas

### Duplica√ß√£o de Scripts
- `mobile-design/scripts/mobile_audit.py` vs `ui-ux-pro-max/scripts/design_system.py`
  - Overlap: Fun√ß√µes de an√°lise de contraste
  - Proposta: Extrair para biblioteca comum
```

### 2.3 Documentos √ìrf√£os (Dangling Documents)

**Defini√ß√£o**: Skills/agents que n√£o s√£o referenciados por nenhum outro documento

**Como Detectar**:

```python
# Algoritmo de Detec√ß√£o de √ìrf√£os
1. Construir grafo de refer√™ncias:
   - N√≥s: Todos os documentos (agents, skills, rules, commands)
   - Arestas: Links/refer√™ncias entre documentos

2. Identificar n√≥s com in-degree = 0:
   - Skills sem refer√™ncias de agents
   - Agents sem refer√™ncias de commands/rules
   - Referencias internas que n√£o apontam para nada

3. Verificar se s√£o entry points v√°lidos:
   - Rules sempre s√£o entry points
   - Commands sempre s√£o entry points
   - Agents referenciados em gemini.md s√£o entry points
   - Skills referenciadas em agent frontmatter s√£o entry points

4. Documentos √≥rf√£os = n√≥s sem in-degree E n√£o s√£o entry points
```

**Output Esperado**:
```markdown
## Relat√≥rio de Documentos √ìrf√£os

### Skills √ìrf√£s (n√£o referenciadas por nenhum agent)
- **rust-pro**: Nenhum agent lista essa skill
  - A√ß√£o: Adicionar ao backend-specialist ou deprecar

### Referencias Quebradas
- `.agent/agents/frontend-specialist.md` referencia `ui-framework-chooser`
  - Skill n√£o existe em nenhuma plataforma
  - A√ß√£o: Remover refer√™ncia ou criar skill

### Scripts √ìrf√£os
- `.cursor/skills/performance-profiling/scripts/unused_analyzer.py`
  - N√£o √© mencionado no SKILL.mdc
  - A√ß√£o: Documentar uso ou remover
```

---

## üí° Fase 3: Propostas de Simplifica√ß√£o

### 3.1 Estrat√©gias de Merge

**Estrat√©gia 1: Merge Vertical (Especializa√ß√£o ‚Üí Gen√©rico)**

```
Quando: Skill espec√≠fica pode ser se√ß√£o de skill gen√©rica

Exemplo:
  ANTES: 
    - testing-patterns (gen√©rico)
    - tdd-workflow (espec√≠fico)
    - test-driven-development (espec√≠fico)
  
  DEPOIS:
    - testing-patterns (√∫nico)
      - Se√ß√£o: TDD Workflow
      - Se√ß√£o: BDD Patterns
      - Se√ß√£o: Integration Testing
```

**Estrat√©gia 2: Merge Horizontal (Similar Nivel ‚Üí Consolidado)**

```
Quando: 2+ skills/agents de mesmo n√≠vel com overlap alto

Exemplo:
  ANTES:
    - product-manager
    - product-owner
  
  DEPOIS:
    - product-specialist
      - Perfis: Manager Mode vs Owner Mode
      - Se√ß√£o: Product Strategy (PM)
      - Se√ß√£o: Backlog Management (PO)
```

**Estrat√©gia 3: Extra√ß√£o de Common Core**

```
Quando: M√∫ltiplas skills compartilham conte√∫do comum

Exemplo:
  ANTES:
    - frontend-design (com color system, typography)
    - mobile-design (com color system, typography)
    - ui-ux-pro-max (com color system, typography)
  
  DEPOIS:
    - design-fundamentals (novo - core common)
    - frontend-design (espec√≠fico web)
    - mobile-design (espec√≠fico mobile)
    - ui-ux-pro-max (avan√ßado/tools)
```

**Estrat√©gia 4: Deprecation (Remover sem Substituir)**

```
Quando: Skill/agent raramente usado e funcionalidade n√£o √© cr√≠tica

Exemplo:
  - using-superpowers ‚Üí Conte√∫do pode ir para README.md
  - update-cursor-settings ‚Üí Espec√≠fico demais, pode ser script
```

### 3.2 Matriz de Decis√£o para Merge

Para cada par de candidatos a merge, avaliar:

| Crit√©rio | Peso | Score (0-10) | Coment√°rio |
|----------|------|--------------|------------|
| **Similaridade de Conte√∫do** | 30% | ? | >8 = forte candidato |
| **Overlap de Dom√≠nio** | 25% | ? | >7 = forte candidato |
| **Ambiguidade de Ativa√ß√£o** | 20% | ? | >6 = confus√£o de LLM |
| **Baixo Uso Individual** | 15% | ? | >5 = pouco impacto |
| **Facilidade de Merge** | 10% | ? | >7 = merge simples |
| **SCORE TOTAL** | 100% | **?** | >7.0 = MERGE RECOMENDADO |

### 3.3 Template de Proposta de Simplifica√ß√£o

Para cada merge/simplifica√ß√£o proposta:

```markdown
## Proposta: Merge de [A] e [B]

### An√°lise
- **Overlap de Conte√∫do**: X%
- **Overlap de Dom√≠nio**: Y%
- **Score de Decis√£o**: Z/10
- **Severidade**: Alta/M√©dia/Baixa

### Justificativa
[Explicar por que o merge faz sentido]

### Estrat√©gia
- Tipo: Merge Vertical / Horizontal / Extra√ß√£o / Deprecation
- Documento Resultante: [nome]
- Plataformas Afetadas: .agent, .claude, .cursor

### Conte√∫do Resultante
**Estrutura Proposta**:
```
# [Nome da Skill/Agent Consolidado]

## Se√ß√£o 1: [de A]
...

## Se√ß√£o 2: [de B]
...

## Se√ß√£o 3: [novo - unifica√ß√£o]
...
```

### Impacto em Refer√™ncias

**Agents que referenciam A**:
- frontend-specialist.md ‚Üí Atualizar para novo nome
- backend-specialist.md ‚Üí Atualizar para novo nome

**Skills que referenciam A**:
- app-builder/SKILL.md linha 45 ‚Üí Atualizar link
- architecture/SKILL.md linha 120 ‚Üí Atualizar link

**Agents que referenciam B**:
- [lista]

**Skills que referenciam B**:
- [lista]

### Plano de Migra√ß√£o

**Fase 1: Prepara√ß√£o**
1. Criar nova skill consolidada em `.agent/skills/[novo-nome]/`
2. Migrar conte√∫do consolidado de A e B
3. Reconciliar links internos

**Fase 2: Atualiza√ß√£o de Refer√™ncias**
1. Atualizar frontmatter de agents que usam A ou B
2. Atualizar links em outras skills
3. Verificar dangling documents

**Fase 3: Sincroniza√ß√£o Cross-Platform**
1. Replicar para `.claude/skills/[novo-nome]/SKILL.md`
2. Replicar para `.cursor/skills/[novo-nome]/SKILL.mdc`
3. Ajustar platform-specific paths

**Fase 4: Deprecation**
1. Mover A e B para `.deprecated/` (n√£o deletar ainda)
2. Adicionar warning em A e B apontando para novo
3. Validar sem erros de refer√™ncias

**Fase 5: Cleanup**
1. Ap√≥s per√≠odo de valida√ß√£o, deletar A e B
2. Atualizar documenta√ß√£o (toc.md, ARCHITECTURE.md)

### Valida√ß√£o
- [ ] Script de links n√£o retorna erros
- [ ] Nenhum documento √≥rf√£o criado
- [ ] Conte√∫do sincronizado nas 3 plataformas
- [ ] Metadata corretas por plataforma
- [ ] Tests e scripts migrados

### Risco
- **Baixo**: Merge simples, poucas refer√™ncias
- **M√©dio**: Merge com reestrutura√ß√£o, m√∫ltiplas refer√™ncias
- **Alto**: Merge de componentes core, muitas depend√™ncias
```

---

## üõ†Ô∏è Fase 4: Execu√ß√£o e Reconcilia√ß√£o

### 4.1 Reconcilia√ß√£o de Links

**Algoritmo**:

```python
# Reconcilia√ß√£o de Links Durante Merge
def reconcile_links_on_merge(old_skill_A, old_skill_B, new_skill):
    """
    Reconcilia todos os links quando A e B s√£o mesclados em new_skill
    """
    all_platforms = ['.agent', '.claude', '.cursor']
    
    for platform in all_platforms:
        # 1. Encontrar todos os arquivos que referenciam A ou B
        referencing_files = find_files_referencing(
            platform, 
            [old_skill_A, old_skill_B]
        )
        
        for file_path in referencing_files:
            # 2. Substituir refer√™ncias
            content = read_file(file_path)
            
            # Substituir refer√™ncias em frontmatter (skills: list)
            content = replace_in_frontmatter(
                content,
                old_values=[old_skill_A, old_skill_B],
                new_value=new_skill
            )
            
            # Substituir links markdown
            content = replace_markdown_links(
                content,
                old_paths=[
                    f'{platform}/skills/{old_skill_A}',
                    f'{platform}/skills/{old_skill_B}'
                ],
                new_path=f'{platform}/skills/{new_skill}'
            )
            
            # Substituir refer√™ncias textuais
            content = replace_text_references(
                content,
                old_names=[old_skill_A, old_skill_B],
                new_name=new_skill
            )
            
            write_file(file_path, content)
        
        # 3. Verificar √≥rf√£os
        check_for_orphans(platform)
        
        # 4. Validar links
        validate_all_links(platform)
```

### 4.2 Detec√ß√£o de √ìrf√£os P√≥s-Merge

```python
def detect_dangling_docs_after_merge(deleted_docs, platform):
    """
    Ap√≥s deletar/mover docs A e B, verificar se criamos √≥rf√£os
    """
    all_docs = get_all_documents(platform)
    reference_graph = build_reference_graph(all_docs)
    
    # Entry points: rules, commands, agents listados em gemini.md
    entry_points = get_entry_points(platform)
    
    # Busca em largura a partir de entry points
    reachable = breadth_first_search(reference_graph, entry_points)
    
    # Documentos n√£o alcan√ß√°veis = √≥rf√£os
    orphans = set(all_docs) - reachable
    
    # Filtrar false positives (assets, scripts internos, etc)
    true_orphans = filter_true_orphans(orphans)
    
    return true_orphans
```

### 4.3 Sincroniza√ß√£o Cross-Platform

**Protocolo de Sincroniza√ß√£o**:

```markdown
Para cada modifica√ß√£o em Platform A:

1. **Extrair Conte√∫do Core**
   - Ler arquivo modificado em Platform A
   - Separar metadata de conte√∫do
   - Normalizar conte√∫do (remover refs espec√≠ficas de A)

2. **Encontrar Equivalente nas Outras Plataformas**
   - Platform B: mesmo nome, extens√£o B-specific
   - Platform C: mesmo nome, extens√£o C-specific
   - Se n√£o existir: criar

3. **Aplicar Conte√∫do**
   - Preservar metadata espec√≠fica de B e C
   - Aplicar conte√∫do normalizado
   - Ajustar platform-specific paths:
     - `.agent/` ‚Üí `.claude/` ou `.cursor/`
     - `SKILL.md` ‚Üí `SKILL.mdc` (se .cursor)

4. **Validar**
   - Content hash deve ser similar (ap√≥s normaliza√ß√£o)
   - Links devem apontar para mesma estrutura relativa
   - Metadata deve seguir specs da plataforma

5. **Commit At√¥mico**
   - Commitar as 3 plataformas juntas
   - Mensagem: "sync: [descri√ß√£o] across platforms"
```

---

## üìã Fase 5: Relat√≥rios e M√©tricas

### 5.1 Relat√≥rio de Simplifica√ß√£o

```markdown
# Relat√≥rio de Simplifica√ß√£o do Ecossistema

## Executive Summary

**Objetivo**: Reduzir complexidade mantendo qualidade e funcionalidade

**Resultados**:
- Skills: 75 ‚Üí 52 (31% redu√ß√£o)
- Agents: 20 ‚Üí 17 (15% redu√ß√£o)
- Linhas de documenta√ß√£o: ~45,000 ‚Üí ~32,000 (29% redu√ß√£o)
- Duplica√ß√£o de conte√∫do: 35% ‚Üí 8%
- Documentos √≥rf√£os: 12 ‚Üí 0

## Detalhamento

### Skills Mescladas (23)

| Antes | Depois | Estrat√©gia | Impacto |
|-------|--------|------------|---------|
| test-driven-development + tdd-workflow | testing-patterns (expandido) | Merge Vertical | 15 refer√™ncias atualizadas |
| product-manager + product-owner | product-specialist | Merge Horizontal | 8 refer√™ncias atualizadas |
| ... | ... | ... | ... |

### Agents Mesclados (3)

| Antes | Depois | Estrat√©gia | Impacto |
|-------|--------|------------|---------|
| test-engineer + qa-automation-engineer | qa-specialist | Merge Horizontal | 12 refer√™ncias atualizadas |
| ... | ... | ... | ... |

### Skills Deprecadas (5)

| Skill | Raz√£o | Conte√∫do Migrado Para |
|-------|-------|----------------------|
| using-superpowers | Muito espec√≠fico | README.md |
| update-cursor-settings | Operacional | Script utilit√°rio |
| ... | ... | ... |

## Melhorias de Qualidade

### Ambiguidade de Ativa√ß√£o
- Antes: Score m√©dio 6.2/10 (alto = ruim)
- Depois: Score m√©dio 2.8/10 (baixo = bom)

### Clareza de Dom√≠nio
- Overlaps >40%: 18 pares ‚Üí 3 pares
- Overlaps >60%: 5 pares ‚Üí 0 pares

### Manutenibilidade
- Documentos com duplica√ß√£o: 42 ‚Üí 9
- Scripts duplicados: 8 pares ‚Üí 0 pares
- Links quebrados: 23 ‚Üí 0

## Impacto Cross-Platform

- Arquivos modificados: 180 (60 por plataforma)
- Commits de sincroniza√ß√£o: 35
- Content hash accuracy: 98.5%
- Links reconciliados: 456
- Zero documentos √≥rf√£os criados

## Valida√ß√£o

- ‚úÖ `ecosystem_audit.py --fail-on=high`: PASS
- ‚úÖ Todos os links v√°lidos em todas as plataformas
- ‚úÖ Metadata specs respeitadas por plataforma
- ‚úÖ Conte√∫do sincronizado (hash similarity >95%)
- ‚úÖ Nenhum documento √≥rf√£o
- ‚úÖ Testes de ativa√ß√£o de LLM: 100% sucesso

## Recomenda√ß√µes Futuras

1. **Revis√£o Trimestral**: Auditar overlaps a cada 3 meses
2. **Freeze de Novos Skills**: Avaliar necessidade antes de criar novos
3. **Monitoramento de Uso**: Implementar telemetria para identificar skills pouco usadas
4. **Automa√ß√£o**: Script de detec√ß√£o de duplica√ß√£o em CI/CD
```

### 5.2 M√©tricas de Sucesso

| M√©trica | Baseline | Meta | Resultado | Status |
|---------|----------|------|-----------|--------|
| **Duplica√ß√£o de Conte√∫do** | 35% | <10% | 8% | ‚úÖ |
| **Overlaps de Dom√≠nio >40%** | 18 pares | <5 pares | 3 pares | ‚úÖ |
| **Documentos √ìrf√£os** | 12 | 0 | 0 | ‚úÖ |
| **Ambiguidade M√©dia** | 6.2/10 | <3.5/10 | 2.8/10 | ‚úÖ |
| **Redu√ß√£o de Skills** | 75 | 60 | 52 | ‚úÖ |
| **Redu√ß√£o de Agents** | 20 | 18 | 17 | ‚úÖ |
| **Sincroniza√ß√£o Cross-Platform** | 87% | 95% | 98.5% | ‚úÖ |
| **Links Quebrados** | 23 | 0 | 0 | ‚úÖ |

---

## üöÄ Plano de Execu√ß√£o Sugerido

### Sprint 1: An√°lise e Invent√°rio (3-5 dias)
- [ ] Executar an√°lise de dom√≠nio completa
- [ ] Gerar relat√≥rios de invas√£o e duplica√ß√£o
- [ ] Identificar candidatos para merge (top 20)
- [ ] Calcular matriz de decis√£o para cada candidato

### Sprint 2: Propostas Detalhadas (2-3 dias)
- [ ] Criar proposta detalhada para cada merge
- [ ] Validar propostas (revis√£o por humano ou LLM experiente)
- [ ] Priorizar por impacto e risco
- [ ] Criar plano de migra√ß√£o por merge

### Sprint 3-4: Execu√ß√£o de Merges (5-7 dias)
- [ ] Executar merges de baixo risco primeiro
- [ ] Reconciliar links em cada merge
- [ ] Sincronizar cross-platform ap√≥s cada merge
- [ ] Validar aus√™ncia de √≥rf√£os ap√≥s cada merge
- [ ] Commit at√¥mico por merge

### Sprint 5: Valida√ß√£o e Ajustes (2-3 dias)
- [ ] Executar ecosystem_audit.py
- [ ] Testar ativa√ß√£o de LLM em cen√°rios reais
- [ ] Ajustar descri√ß√µes se houver ambiguidade
- [ ] Validar links em todas as plataformas
- [ ] Gerar relat√≥rio final

### Sprint 6: Documenta√ß√£o (1-2 dias)
- [ ] Atualizar ARCHITECTURE.md
- [ ] Atualizar toc.md / toc skill
- [ ] Criar CHANGELOG.md detalhado
- [ ] Documentar decis√µes de merge
- [ ] Criar guia de manuten√ß√£o

---

## üéØ Outputs Esperados

Ao final da execu√ß√£o deste prompt, devem ser gerados:

1. **Relat√≥rios de An√°lise**:
   - `DOMAIN_ANALYSIS_REPORT.md` - Mapeamento de dom√≠nios e overlaps
   - `DUPLICATION_REPORT.md` - Lista de duplica√ß√µes detectadas
   - `INVASION_REPORT.md` - Casos de invas√£o de fun√ß√µes
   - `ORPHAN_DOCUMENTS_REPORT.md` - Documentos sem refer√™ncias

2. **Propostas de Simplifica√ß√£o**:
   - `MERGE_PROPOSALS.md` - Lista de merges propostos com justificativas
   - `DEPRECATION_PROPOSALS.md` - Skills/agents a deprecar
   - `EXTRACTION_PROPOSALS.md` - Common cores a extrair

3. **Planos de Migra√ß√£o**:
   - `MIGRATION_PLAN_[MERGE_NAME].md` (um por merge)
   - `CROSS_PLATFORM_SYNC_PLAN.md`

4. **Scripts de Automa√ß√£o**:
   - `detect_domain_overlap.py` - Detectar overlaps automaticamente
   - `detect_content_duplication.py` - Detectar duplica√ß√µes
   - `detect_orphans.py` - Detectar √≥rf√£os
   - `reconcile_links.py` - Reconciliar links durante merges
   - `sync_cross_platform.py` - Sincronizar entre plataformas

5. **Relat√≥rio Final**:
   - `SIMPLIFICATION_REPORT.md` - Relat√≥rio executivo completo
   - `METRICS_BEFORE_AFTER.json` - M√©tricas comparativas

---

## üîß Scripts de Apoio Recomendados

### Script 1: An√°lise de Overlap de Dom√≠nio

```python
#!/usr/bin/env python3
"""
detect_domain_overlap.py - Detecta overlap de dom√≠nios entre agentes/skills
"""

import yaml
from pathlib import Path
from typing import Dict, List, Set, Tuple
from collections import defaultdict
import difflib

def extract_domains_from_description(description: str) -> Set[str]:
    """
    Extrai dom√≠nios de uma descri√ß√£o usando keywords
    """
    keywords = {
        'frontend': ['react', 'vue', 'ui', 'css', 'html', 'component', 'styling', 'responsive'],
        'backend': ['api', 'server', 'nodejs', 'python', 'endpoint', 'middleware'],
        'database': ['sql', 'nosql', 'schema', 'migration', 'query', 'orm'],
        'testing': ['test', 'tdd', 'bdd', 'unit', 'integration', 'e2e', 'playwright'],
        'security': ['auth', 'security', 'vulnerability', 'owasp', 'encryption'],
        'devops': ['deploy', 'ci/cd', 'docker', 'kubernetes', 'pipeline'],
        'mobile': ['ios', 'android', 'react native', 'flutter', 'mobile'],
        'design': ['ux', 'ui', 'design', 'typography', 'color', 'layout'],
        'performance': ['performance', 'optimization', 'profiling', 'metrics'],
    }
    
    desc_lower = description.lower()
    detected_domains = set()
    
    for domain, terms in keywords.items():
        if any(term in desc_lower for term in terms):
            detected_domains.add(domain)
    
    return detected_domains

def calculate_overlap(domains_a: Set[str], domains_b: Set[str]) -> float:
    """
    Calcula % de overlap entre dois conjuntos de dom√≠nios
    """
    if not domains_a or not domains_b:
        return 0.0
    
    intersection = domains_a & domains_b
    union = domains_a | domains_b
    
    return (len(intersection) / len(union)) * 100 if union else 0.0

def analyze_domain_overlaps(workspace: Path, category: str) -> Dict:
    """
    Analisa overlaps para uma categoria (agents ou skills)
    """
    platforms = ['.agent', '.claude', '.cursor']
    items = {}
    
    # Coletar de uma plataforma (assume .agent como source of truth)
    if category == 'agents':
        items_dir = workspace / '.agent' / 'agents'
        for file_path in items_dir.glob('*.md'):
            with open(file_path, 'r') as f:
                content = f.read()
                # Extrair descri√ß√£o (assumindo format padr√£o)
                # Voc√™ pode melhorar isso parseando YAML frontmatter
                items[file_path.stem] = extract_domains_from_description(content)
    
    elif category == 'skills':
        items_dir = workspace / '.agent' / 'skills'
        for skill_dir in items_dir.iterdir():
            if skill_dir.is_dir():
                skill_file = skill_dir / 'SKILL.md'
                if skill_file.exists():
                    with open(skill_file, 'r') as f:
                        content = f.read()
                        items[skill_dir.name] = extract_domains_from_description(content)
    
    # Calcular overlaps entre todos os pares
    overlaps = []
    item_names = list(items.keys())
    
    for i in range(len(item_names)):
        for j in range(i + 1, len(item_names)):
            name_a = item_names[i]
            name_b = item_names[j]
            overlap_pct = calculate_overlap(items[name_a], items[name_b])
            
            if overlap_pct > 20:  # Threshold: 20%
                overlaps.append({
                    'pair': (name_a, name_b),
                    'overlap_pct': overlap_pct,
                    'domains_a': items[name_a],
                    'domains_b': items[name_b],
                    'common_domains': items[name_a] & items[name_b]
                })
    
    # Ordenar por overlap descendente
    overlaps.sort(key=lambda x: x['overlap_pct'], reverse=True)
    
    return overlaps

def generate_overlap_report(overlaps: List[Dict], category: str) -> str:
    """
    Gera relat√≥rio markdown de overlaps
    """
    lines = [f"# Relat√≥rio de Overlap de Dom√≠nios - {category.title()}\n"]
    lines.append(f"Total de pares com overlap >20%: {len(overlaps)}\n")
    lines.append("---\n")
    
    # Severidade
    high = [o for o in overlaps if o['overlap_pct'] >= 60]
    medium = [o for o in overlaps if 40 <= o['overlap_pct'] < 60]
    low = [o for o in overlaps if 20 <= o['overlap_pct'] < 40]
    
    for severity, items in [('Alta (‚â•60%)', high), ('M√©dia (40-59%)', medium), ('Baixa (20-39%)', low)]:
        lines.append(f"## {severity} - {len(items)} pares\n")
        
        for item in items:
            name_a, name_b = item['pair']
            lines.append(f"### {name_a} ‚Üî {name_b}\n")
            lines.append(f"- **Overlap**: {item['overlap_pct']:.1f}%\n")
            lines.append(f"- **Dom√≠nios Comuns**: {', '.join(item['common_domains'])}\n")
            lines.append(f"- **Proposta**: ANALISAR PARA MERGE\n")
            lines.append("\n")
    
    return ''.join(lines)

if __name__ == '__main__':
    workspace = Path('/workspace')
    
    print("Analisando overlaps de AGENTS...")
    agent_overlaps = analyze_domain_overlaps(workspace, 'agents')
    report_agents = generate_overlap_report(agent_overlaps, 'agents')
    
    with open(workspace / 'docs/refactoring/reports/AGENT_DOMAIN_OVERLAPS.md', 'w') as f:
        f.write(report_agents)
    
    print(f"‚úì Relat√≥rio de agents gerado: {len(agent_overlaps)} overlaps detectados")
    
    print("Analisando overlaps de SKILLS...")
    skill_overlaps = analyze_domain_overlaps(workspace, 'skills')
    report_skills = generate_overlap_report(skill_overlaps, 'skills')
    
    with open(workspace / 'docs/refactoring/reports/SKILL_DOMAIN_OVERLAPS.md', 'w') as f:
        f.write(report_skills)
    
    print(f"‚úì Relat√≥rio de skills gerado: {len(skill_overlaps)} overlaps detectados")
```

### Script 2: Detec√ß√£o de Conte√∫do Duplicado

```python
#!/usr/bin/env python3
"""
detect_content_duplication.py - Detecta duplica√ß√£o de conte√∫do entre skills
"""

import hashlib
import re
from pathlib import Path
from typing import Dict, List, Tuple
from difflib import SequenceMatcher

def normalize_content(content: str) -> str:
    """
    Normaliza conte√∫do removendo metadata e refs espec√≠ficas
    """
    # Remover frontmatter
    content = re.sub(r'^---\s*\n.*?\n---\s*\n', '', content, flags=re.DOTALL)
    
    # Remover platform-specific paths
    content = re.sub(r'\.agent/', '{platform}/', content)
    content = re.sub(r'\.claude/', '{platform}/', content)
    content = re.sub(r'\.cursor/', '{platform}/', content)
    
    # Normalizar whitespace
    content = re.sub(r'\s+', ' ', content)
    
    return content.strip()

def calculate_similarity(content_a: str, content_b: str) -> float:
    """
    Calcula similaridade entre dois conte√∫dos (0-100%)
    """
    return SequenceMatcher(None, content_a, content_b).ratio() * 100

def detect_duplications(workspace: Path) -> List[Dict]:
    """
    Detecta duplica√ß√µes entre skills
    """
    skills_data = {}
    
    # Ler todas as skills de .agent
    skills_dir = workspace / '.agent' / 'skills'
    for skill_dir in skills_dir.iterdir():
        if skill_dir.is_dir():
            skill_file = skill_dir / 'SKILL.md'
            if skill_file.exists():
                content = skill_file.read_text()
                normalized = normalize_content(content)
                skills_data[skill_dir.name] = {
                    'content': normalized,
                    'size': len(normalized)
                }
    
    # Comparar todos os pares
    duplications = []
    skill_names = list(skills_data.keys())
    
    for i in range(len(skill_names)):
        for j in range(i + 1, len(skill_names)):
            name_a = skill_names[i]
            name_b = skill_names[j]
            
            similarity = calculate_similarity(
                skills_data[name_a]['content'],
                skills_data[name_b]['content']
            )
            
            if similarity > 60:  # Threshold
                duplications.append({
                    'pair': (name_a, name_b),
                    'similarity_pct': similarity,
                    'size_a': skills_data[name_a]['size'],
                    'size_b': skills_data[name_b]['size']
                })
    
    duplications.sort(key=lambda x: x['similarity_pct'], reverse=True)
    return duplications

def generate_duplication_report(duplications: List[Dict]) -> str:
    """
    Gera relat√≥rio de duplica√ß√µes
    """
    lines = ["# Relat√≥rio de Duplica√ß√£o de Conte√∫do\n\n"]
    lines.append(f"Total de pares com similaridade >60%: {len(duplications)}\n\n")
    lines.append("---\n\n")
    
    complete = [d for d in duplications if d['similarity_pct'] >= 80]
    partial = [d for d in duplications if 60 <= d['similarity_pct'] < 80]
    
    lines.append(f"## Duplica√ß√£o Completa (‚â•80%) - {len(complete)} pares\n\n")
    for dup in complete:
        name_a, name_b = dup['pair']
        lines.append(f"### {name_a} ‚Üî {name_b}\n")
        lines.append(f"- **Similaridade**: {dup['similarity_pct']:.1f}%\n")
        lines.append(f"- **Tamanhos**: {dup['size_a']} vs {dup['size_b']} chars\n")
        lines.append(f"- **Proposta**: MERGE OBRIGAT√ìRIO\n\n")
    
    lines.append(f"## Duplica√ß√£o Parcial (60-79%) - {len(partial)} pares\n\n")
    for dup in partial:
        name_a, name_b = dup['pair']
        lines.append(f"### {name_a} ‚Üî {name_b}\n")
        lines.append(f"- **Similaridade**: {dup['similarity_pct']:.1f}%\n")
        lines.append(f"- **Tamanhos**: {dup['size_a']} vs {dup['size_b']} chars\n")
        lines.append(f"- **Proposta**: ANALISAR SE√á√ïES DUPLICADAS\n\n")
    
    return ''.join(lines)

if __name__ == '__main__':
    workspace = Path('/workspace')
    
    print("Detectando duplica√ß√µes de conte√∫do...")
    duplications = detect_duplications(workspace)
    
    report = generate_duplication_report(duplications)
    
    output_path = workspace / 'docs/refactoring/reports/CONTENT_DUPLICATION_REPORT.md'
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w') as f:
        f.write(report)
    
    print(f"‚úì Relat√≥rio gerado: {len(duplications)} duplica√ß√µes detectadas")
    print(f"‚úì Salvo em: {output_path}")
```

### Script 3: Detec√ß√£o de Documentos √ìrf√£os

```python
#!/usr/bin/env python3
"""
detect_orphans.py - Detecta documentos √≥rf√£os (sem refer√™ncias)
"""

import re
from pathlib import Path
from typing import Dict, Set, List
from collections import defaultdict

def build_reference_graph(workspace: Path, platform: str) -> Dict[str, Set[str]]:
    """
    Constr√≥i grafo de refer√™ncias para uma plataforma
    Returns: {documento: set(documentos_que_referencia)}
    """
    graph = defaultdict(set)
    platform_dir = workspace / platform
    
    # Padr√µes de refer√™ncia
    skill_ref_pattern = re.compile(r'skills:\s*([^\n]+)', re.MULTILINE)
    link_pattern = re.compile(r'\[([^\]]+)\]\(([^)]+)\)')
    
    # Percorrer todos os .md/.mdc files
    for file_path in platform_dir.rglob('*'):
        if file_path.suffix not in ['.md', '.mdc']:
            continue
        
        try:
            content = file_path.read_text()
        except:
            continue
        
        doc_id = str(file_path.relative_to(platform_dir))
        
        # Refer√™ncias em frontmatter (skills:)
        for match in skill_ref_pattern.finditer(content):
            skills_str = match.group(1)
            skills = [s.strip() for s in skills_str.split(',')]
            for skill in skills:
                if skill:
                    graph[doc_id].add(f'skills/{skill}/SKILL')
        
        # Refer√™ncias em links markdown
        for match in link_pattern.finditer(content):
            link_target = match.group(2)
            
            # Ignorar links externos e √¢ncoras
            if link_target.startswith(('http', '#')):
                continue
            
            # Normalizar path
            if link_target.startswith('./'):
                link_target = link_target[2:]
            
            # Resolver relativo ao arquivo atual
            target_path = (file_path.parent / link_target).resolve()
            
            try:
                target_rel = target_path.relative_to(platform_dir)
                graph[doc_id].add(str(target_rel))
            except:
                pass
    
    return graph

def find_entry_points(workspace: Path, platform: str) -> Set[str]:
    """
    Identifica entry points (documentos que s√£o pontos de entrada v√°lidos)
    """
    entry_points = set()
    
    # Rules s√£o sempre entry points
    rules_dir = workspace / platform / 'rules'
    if rules_dir.exists():
        for rule_file in rules_dir.glob('*'):
            entry_points.add(str(rule_file.relative_to(workspace / platform)))
    
    # Commands/workflows s√£o entry points
    if platform == '.agent':
        cmd_dir = workspace / platform / 'workflows'
    else:
        cmd_dir = workspace / platform / 'commands'
    
    if cmd_dir.exists():
        for cmd_file in cmd_dir.glob('*.md'):
            entry_points.add(str(cmd_file.relative_to(workspace / platform)))
    
    # Agents s√£o entry points
    agents_dir = workspace / platform / 'agents'
    if agents_dir.exists():
        for agent_file in agents_dir.glob('*.md'):
            entry_points.add(str(agent_file.relative_to(workspace / platform)))
    
    return entry_points

def find_reachable(graph: Dict[str, Set[str]], entry_points: Set[str]) -> Set[str]:
    """
    BFS para encontrar todos os documentos alcan√ß√°veis a partir dos entry points
    """
    reachable = set(entry_points)
    queue = list(entry_points)
    
    while queue:
        current = queue.pop(0)
        
        if current in graph:
            for neighbor in graph[current]:
                if neighbor not in reachable:
                    reachable.add(neighbor)
                    queue.append(neighbor)
    
    return reachable

def detect_orphans(workspace: Path, platform: str) -> List[str]:
    """
    Detecta documentos √≥rf√£os em uma plataforma
    """
    # Todos os documentos
    platform_dir = workspace / platform
    all_docs = set()
    
    for category in ['agents', 'skills', 'rules', 'commands', 'workflows']:
        cat_dir = platform_dir / category
        if cat_dir.exists():
            for file_path in cat_dir.rglob('*'):
                if file_path.suffix in ['.md', '.mdc']:
                    all_docs.add(str(file_path.relative_to(platform_dir)))
    
    # Grafo e entry points
    graph = build_reference_graph(workspace, platform)
    entry_points = find_entry_points(workspace, platform)
    
    # Documentos alcan√ß√°veis
    reachable = find_reachable(graph, entry_points)
    
    # √ìrf√£os = n√£o alcan√ß√°veis
    orphans = sorted(all_docs - reachable)
    
    return orphans

def generate_orphans_report(workspace: Path) -> str:
    """
    Gera relat√≥rio de √≥rf√£os para todas as plataformas
    """
    lines = ["# Relat√≥rio de Documentos √ìrf√£os\n\n"]
    
    platforms = ['.agent', '.claude', '.cursor']
    
    for platform in platforms:
        orphans = detect_orphans(workspace, platform)
        
        lines.append(f"## {platform}\n\n")
        
        if not orphans:
            lines.append("‚úÖ Nenhum documento √≥rf√£o detectado.\n\n")
        else:
            lines.append(f"‚ùå **{len(orphans)} documentos √≥rf√£os detectados:**\n\n")
            
            for orphan in orphans:
                lines.append(f"- `{orphan}`\n")
                
                # A√ß√£o sugerida
                if 'skills/' in orphan:
                    lines.append(f"  - **A√ß√£o**: Adicionar √† lista `skills:` de algum agent\n")
                elif 'agents/' in orphan:
                    lines.append(f"  - **A√ß√£o**: Referenciar em command ou gemini.md\n")
                else:
                    lines.append(f"  - **A√ß√£o**: Analisar se ainda √© necess√°rio\n")
            
            lines.append("\n")
    
    return ''.join(lines)

if __name__ == '__main__':
    workspace = Path('/workspace')
    
    print("Detectando documentos √≥rf√£os...")
    report = generate_orphans_report(workspace)
    
    output_path = workspace / 'docs/refactoring/reports/ORPHAN_DOCUMENTS_REPORT.md'
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w') as f:
        f.write(report)
    
    print(f"‚úì Relat√≥rio gerado: {output_path}")
```

---

## üìö Refer√™ncias

- Audit Script Existente: `/workspace/scripts/ecosystem/ecosystem_audit.py`
- Documenta√ß√£o Anterior: `/workspace/docs/refactoring/ECOSYSTEM_REVIEW_PROMPT.md`
- Arquitetura: `/workspace/.cursor/ARCHITECTURE.md` (e equivalentes)

---

## ‚úÖ Checklist de Completude

Ao executar este prompt, verifique se todos os itens foram cobertos:

- [ ] An√°lise de dom√≠nio completa (agents e skills)
- [ ] Relat√≥rios de invas√£o de fun√ß√µes gerados
- [ ] Relat√≥rios de duplica√ß√£o de conte√∫do gerados
- [ ] Relat√≥rios de documentos √≥rf√£os gerados
- [ ] Matriz de decis√£o calculada para candidatos a merge
- [ ] Propostas detalhadas criadas para cada simplifica√ß√£o
- [ ] Planos de migra√ß√£o documentados
- [ ] Scripts de automa√ß√£o desenvolvidos
- [ ] Execu√ß√£o de merges com reconcilia√ß√£o de links
- [ ] Sincroniza√ß√£o cross-platform validada
- [ ] Aus√™ncia de documentos √≥rf√£os p√≥s-merge confirmada
- [ ] Ecosystem audit script executado com sucesso
- [ ] Relat√≥rio final de simplifica√ß√£o gerado
- [ ] M√©tricas before/after documentadas
- [ ] Documenta√ß√£o atualizada (ARCHITECTURE.md, toc, etc)

---

**Vers√£o**: 1.0  
**Data**: 2026-02-10  
**Autor**: Sistema de Simplifica√ß√£o de Ecossistema  
**Status**: Pronto para Execu√ß√£o
